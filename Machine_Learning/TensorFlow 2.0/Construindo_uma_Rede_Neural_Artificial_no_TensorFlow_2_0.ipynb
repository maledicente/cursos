{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Construindo uma Rede Neural Artificial no TensorFlow 2.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJr4nMgyb9oS"
      },
      "source": [
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png\" />\n",
        "  Image source: https://www.kaggle.com/\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVF9I9v6Zipb"
      },
      "source": [
        "## Etapa 1: Instalando o TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF9QcxIk_Sy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe361801-7f63-4c15-c35d-352c02fac20a"
      },
      "source": [
        "!pip uninstall -y tensorflow #Comando necessário, pois o TensorFlow-gpu não desinstala a versão mais recente do Tensorflow, pode gerar conflitos."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS6fShx3Za4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83800e42-8876-42f4-b954-e914f0894b9d"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0.alpha"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 49.5MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (0.36.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha) (1.34.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha) (3.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha) (50.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha) (3.4.0)\n",
            "Installing collected packages: keras-applications, tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjlnjPnjWYFw"
      },
      "source": [
        "## Etapa 2: Importando as bibliotecas e a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt0-hrch6rZw"
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vv9AXUnZW78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6678e009-8b22-4b88-e639-514a0af76c83"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2OiUS-kWkJU"
      },
      "source": [
        "## Etapa 3: Pré-processamento\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfoFiEEXYj1"
      },
      "source": [
        "### Carregando a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lCgz6UC8pKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02325212-3e99-4d08-f5a1-e2a372efdf53"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Noa1UZKpCDfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b259423-edaa-4b72-bbe2-152618d6d844"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFr_QN4CIol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd85b30b-6ec6-4bf5-d2ab-9d1569bffd5b"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64KujWQOCTOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96773c20-22ea-4d23-d91a-598942c39965"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjw0rIOICV2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4d90f4-44d7-4b24-da04-6d5a4d0b7eb6"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go31KdXnktlV"
      },
      "source": [
        "0 0 0 0 0 1 0 0 0 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYxeEHzDXdSs"
      },
      "source": [
        "### Normalizando as imagens\n",
        "\n",
        "Dividimos cada pixel das imagens das bases de treinamento e teste, utilizando o maior valor que é 255\n",
        "\n",
        "Com isso, cada pixel estará na faixa entre 0 e 1. Dessa forma, a rede neural vai treinar mais rápida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvWzsB3G9IU8"
      },
      "source": [
        "X_train = X_train / 255.0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo--rpqo9ZtA"
      },
      "source": [
        "X_test = X_test / 255.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxhA1vvICcgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e202aec-f79e-4f1e-e85c-b042ae7e5719"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.53787005e-05, 0.00000000e+00, 0.00000000e+00, 1.99923106e-04,\n",
              "        1.12264514e-03, 0.00000000e+00, 0.00000000e+00, 1.53787005e-05,\n",
              "        6.15148020e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.53787005e-05, 1.53787005e-05, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        4.61361015e-05, 0.00000000e+00, 5.53633218e-04, 2.09150327e-03,\n",
              "        1.95309496e-03, 9.53479431e-04, 8.30449827e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.53787005e-05, 4.61361015e-05,\n",
              "        6.15148020e-05, 0.00000000e+00, 0.00000000e+00, 4.61361015e-05],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        9.22722030e-05, 0.00000000e+00, 1.56862745e-03, 3.13725490e-03,\n",
              "        2.70665129e-03, 2.06074587e-03, 2.21453287e-03, 1.89158016e-03,\n",
              "        3.53710111e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.84544406e-04, 1.53787005e-04, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 2.38369858e-03, 3.62937332e-03,\n",
              "        3.18339100e-03, 2.73740869e-03, 1.64552095e-03, 2.39907728e-03,\n",
              "        2.47597078e-03, 1.67627835e-03, 9.84236832e-04, 3.53710111e-04,\n",
              "        1.18415994e-03, 1.99923106e-03, 1.10726644e-03, 2.30680507e-04],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.53787005e-05,\n",
              "        0.00000000e+00, 1.06113033e-03, 3.18339100e-03, 3.42945021e-03,\n",
              "        3.35255671e-03, 3.32179931e-03, 3.32179931e-03, 2.50672818e-03,\n",
              "        1.95309496e-03, 1.86082276e-03, 1.87620146e-03, 2.24529027e-03,\n",
              "        2.16839677e-03, 1.35332564e-03, 2.64513649e-03, 1.01499423e-03],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.53787005e-05, 1.53787005e-05, 1.53787005e-05,\n",
              "        0.00000000e+00, 3.07574010e-03, 3.56785852e-03, 3.56785852e-03,\n",
              "        3.58323722e-03, 3.52172241e-03, 3.42945021e-03, 3.42945021e-03,\n",
              "        3.30642061e-03, 3.27566321e-03, 2.52210688e-03, 1.95309496e-03,\n",
              "        1.89158016e-03, 3.01422530e-03, 3.52172241e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 2.81430219e-03, 3.46020761e-03, 3.32179931e-03,\n",
              "        3.42945021e-03, 3.50634371e-03, 3.61399462e-03, 3.49096501e-03,\n",
              "        3.44482891e-03, 3.41407151e-03, 3.44482891e-03, 3.39869281e-03,\n",
              "        3.42945021e-03, 3.76778162e-03, 2.66051519e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 2.96808920e-03, 3.50634371e-03, 3.35255671e-03,\n",
              "        3.27566321e-03, 3.04498270e-03, 2.76816609e-03, 3.26028451e-03,\n",
              "        3.22952710e-03, 3.24490581e-03, 3.27566321e-03, 3.42945021e-03,\n",
              "        3.38331411e-03, 3.73702422e-03, 3.10649750e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.53787005e-05, 4.61361015e-05, 0.00000000e+00,\n",
              "        1.84544406e-04, 3.36793541e-03, 3.38331411e-03, 3.26028451e-03,\n",
              "        3.35255671e-03, 2.95271050e-03, 2.59900038e-03, 3.49096501e-03,\n",
              "        3.19876970e-03, 3.35255671e-03, 3.44482891e-03, 3.26028451e-03,\n",
              "        3.47558631e-03, 3.02960400e-03, 3.21414840e-03, 7.99692426e-04],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 9.22722030e-05, 0.00000000e+00,\n",
              "        1.52249135e-03, 3.75240292e-03, 3.41407151e-03, 3.38331411e-03,\n",
              "        3.35255671e-03, 3.12187620e-03, 3.04498270e-03, 3.39869281e-03,\n",
              "        3.30642061e-03, 3.27566321e-03, 3.41407151e-03, 3.38331411e-03,\n",
              "        3.76778162e-03, 1.83006536e-03, 2.56824298e-03, 8.61207228e-04],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 6.15148020e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "        8.45828527e-04, 3.62937332e-03, 3.50634371e-03, 3.53710111e-03,\n",
              "        3.50634371e-03, 3.69088812e-03, 3.56785852e-03, 3.27566321e-03,\n",
              "        3.35255671e-03, 3.42945021e-03, 3.59861592e-03, 3.33717801e-03,\n",
              "        3.33717801e-03, 3.21414840e-03, 1.41484045e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.53787005e-05, 6.15148020e-05,\n",
              "        9.22722030e-05, 1.07650903e-04, 3.07574010e-05, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        3.64475202e-03, 3.47558631e-03, 3.33717801e-03, 3.42945021e-03,\n",
              "        3.41407151e-03, 3.36793541e-03, 3.41407151e-03, 3.39869281e-03,\n",
              "        3.32179931e-03, 3.42945021e-03, 3.52172241e-03, 3.30642061e-03,\n",
              "        3.35255671e-03, 3.92156863e-03, 1.18415994e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 4.61361015e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 9.53479431e-04, 2.22991157e-03, 3.13725490e-03,\n",
              "        3.50634371e-03, 3.18339100e-03, 3.27566321e-03, 3.39869281e-03,\n",
              "        3.35255671e-03, 3.19876970e-03, 3.24490581e-03, 3.35255671e-03,\n",
              "        3.44482891e-03, 3.42945021e-03, 3.36793541e-03, 3.30642061e-03,\n",
              "        3.44482891e-03, 3.75240292e-03, 2.44521338e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        2.76816609e-04, 6.76662822e-04, 1.26105344e-03, 1.64552095e-03,\n",
              "        2.90657439e-03, 3.50634371e-03, 3.38331411e-03, 3.41407151e-03,\n",
              "        3.33717801e-03, 3.47558631e-03, 3.07574010e-03, 3.15263360e-03,\n",
              "        3.24490581e-03, 3.53710111e-03, 3.44482891e-03, 3.59861592e-03,\n",
              "        2.70665129e-03, 2.89119569e-03, 3.84467512e-03, 3.81391772e-03,\n",
              "        3.58323722e-03, 3.66013072e-03, 3.30642061e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 8.76585928e-04, 2.87581699e-03, 3.19876970e-03,\n",
              "        3.44482891e-03, 3.39869281e-03, 3.44482891e-03, 3.19876970e-03,\n",
              "        3.13725490e-03, 3.29104191e-03, 3.19876970e-03, 3.21414840e-03,\n",
              "        3.07574010e-03, 2.44521338e-03, 3.76778162e-03, 2.96808920e-03,\n",
              "        3.16801230e-03, 3.42945021e-03, 3.92156863e-03, 3.92156863e-03,\n",
              "        3.39869281e-03, 3.59861592e-03, 3.39869281e-03, 3.24490581e-03,\n",
              "        3.38331411e-03, 3.56785852e-03, 3.78316032e-03, 0.00000000e+00],\n",
              "       [4.61361015e-05, 3.10649750e-03, 3.50634371e-03, 3.44482891e-03,\n",
              "        3.39869281e-03, 3.24490581e-03, 3.24490581e-03, 3.29104191e-03,\n",
              "        3.15263360e-03, 3.15263360e-03, 3.15263360e-03, 3.38331411e-03,\n",
              "        3.69088812e-03, 1.23029604e-03, 2.30680507e-03, 3.92156863e-03,\n",
              "        3.52172241e-03, 3.39869281e-03, 2.89119569e-03, 2.36831988e-03,\n",
              "        2.93733180e-03, 3.22952710e-03, 3.13725490e-03, 3.21414840e-03,\n",
              "        3.41407151e-03, 3.50634371e-03, 3.46020761e-03, 0.00000000e+00],\n",
              "       [1.50711265e-03, 3.58323722e-03, 3.04498270e-03, 3.22952710e-03,\n",
              "        3.41407151e-03, 3.52172241e-03, 3.52172241e-03, 3.59861592e-03,\n",
              "        3.82929642e-03, 3.38331411e-03, 2.98346790e-03, 3.30642061e-03,\n",
              "        3.33717801e-03, 3.70626682e-03, 9.99615532e-04, 1.12264514e-03,\n",
              "        1.63014225e-03, 1.79930796e-03, 2.58362168e-03, 3.36793541e-03,\n",
              "        3.39869281e-03, 3.30642061e-03, 3.33717801e-03, 3.42945021e-03,\n",
              "        3.42945021e-03, 3.44482891e-03, 3.52172241e-03, 4.45982314e-04],\n",
              "       [1.15340254e-03, 3.13725490e-03, 3.26028451e-03, 3.13725490e-03,\n",
              "        2.96808920e-03, 3.15263360e-03, 3.24490581e-03, 3.46020761e-03,\n",
              "        3.32179931e-03, 2.84505959e-03, 3.02960400e-03, 3.16801230e-03,\n",
              "        3.04498270e-03, 3.27566321e-03, 3.69088812e-03, 2.99884660e-03,\n",
              "        3.49096501e-03, 3.76778162e-03, 3.67550942e-03, 3.42945021e-03,\n",
              "        3.35255671e-03, 3.26028451e-03, 3.21414840e-03, 3.41407151e-03,\n",
              "        3.38331411e-03, 3.39869281e-03, 3.53710111e-03, 1.03037293e-03],\n",
              "       [7.38177624e-04, 3.12187620e-03, 2.81430219e-03, 2.98346790e-03,\n",
              "        3.27566321e-03, 3.02960400e-03, 2.84505959e-03, 2.92195309e-03,\n",
              "        2.98346790e-03, 2.95271050e-03, 3.10649750e-03, 3.29104191e-03,\n",
              "        3.36793541e-03, 3.39869281e-03, 3.38331411e-03, 3.62937332e-03,\n",
              "        3.46020761e-03, 3.32179931e-03, 3.06036140e-03, 3.16801230e-03,\n",
              "        2.86043829e-03, 2.78354479e-03, 2.72202999e-03, 2.64513649e-03,\n",
              "        2.78354479e-03, 3.15263360e-03, 3.16801230e-03, 1.76855056e-03],\n",
              "       [0.00000000e+00, 1.87620146e-03, 3.36793541e-03, 2.96808920e-03,\n",
              "        2.75278739e-03, 2.62975779e-03, 2.81430219e-03, 3.01422530e-03,\n",
              "        3.13725490e-03, 3.22952710e-03, 3.27566321e-03, 3.18339100e-03,\n",
              "        3.24490581e-03, 3.22952710e-03, 3.07574010e-03, 3.01422530e-03,\n",
              "        2.98346790e-03, 2.93733180e-03, 2.99884660e-03, 2.93733180e-03,\n",
              "        3.04498270e-03, 2.95271050e-03, 2.70665129e-03, 2.39907728e-03,\n",
              "        2.56824298e-03, 2.72202999e-03, 3.22952710e-03, 1.41484045e-03],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.13802384e-03, 2.90657439e-03,\n",
              "        3.26028451e-03, 2.93733180e-03, 2.69127259e-03, 2.64513649e-03,\n",
              "        2.69127259e-03, 2.78354479e-03, 2.84505959e-03, 2.89119569e-03,\n",
              "        2.90657439e-03, 2.89119569e-03, 2.96808920e-03, 3.04498270e-03,\n",
              "        3.13725490e-03, 3.21414840e-03, 3.22952710e-03, 3.22952710e-03,\n",
              "        3.24490581e-03, 2.89119569e-03, 2.89119569e-03, 2.98346790e-03,\n",
              "        2.95271050e-03, 3.32179931e-03, 2.61437908e-03, 0.00000000e+00],\n",
              "       [3.07574010e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.01499423e-03, 3.07574010e-03, 3.41407151e-03, 3.64475202e-03,\n",
              "        3.67550942e-03, 3.72164552e-03, 3.78316032e-03, 3.73702422e-03,\n",
              "        3.75240292e-03, 3.39869281e-03, 3.38331411e-03, 2.96808920e-03,\n",
              "        2.93733180e-03, 2.75278739e-03, 2.79892349e-03, 2.79892349e-03,\n",
              "        2.78354479e-03, 2.70665129e-03, 2.55286428e-03, 2.58362168e-03,\n",
              "        1.52249135e-03, 8.91964629e-04, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.15148020e-04,\n",
              "        9.38100730e-04, 6.76662822e-04, 1.10726644e-03, 6.30526720e-04,\n",
              "        5.38254517e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBacLmGIX0Es"
      },
      "source": [
        "### Remodelando (reshaping) a base de dados\n",
        "\n",
        "Como estamos trabalhando com uma rede neural densa, mudamos a dimensão das bases de dados para ficarem no formato de vetor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR6UvdpDChqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4877fe-a5f3-47c2-b136-2a76095a10bf"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tao7pom-grn"
      },
      "source": [
        "# Como a dimensão de cada imagem é 28x28, mudamos toda a base de dados para o formato [-1 (todos os elementos), altura * largura]\n",
        "X_train = X_train.reshape(-1, 28*28)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9MbMrg9-kr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55aceef-6646-4a62-89fc-0dbeb4c6011f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PluazdGHEx2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c432654-0414-4c80-e4f6-8ca651b4b223"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.53787005e-05, 0.00000000e+00, 0.00000000e+00, 1.99923106e-04,\n",
              "       1.12264514e-03, 0.00000000e+00, 0.00000000e+00, 1.53787005e-05,\n",
              "       6.15148020e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.53787005e-05, 1.53787005e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       4.61361015e-05, 0.00000000e+00, 5.53633218e-04, 2.09150327e-03,\n",
              "       1.95309496e-03, 9.53479431e-04, 8.30449827e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.53787005e-05, 4.61361015e-05,\n",
              "       6.15148020e-05, 0.00000000e+00, 0.00000000e+00, 4.61361015e-05,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.22722030e-05, 0.00000000e+00, 1.56862745e-03, 3.13725490e-03,\n",
              "       2.70665129e-03, 2.06074587e-03, 2.21453287e-03, 1.89158016e-03,\n",
              "       3.53710111e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.84544406e-04, 1.53787005e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.38369858e-03, 3.62937332e-03,\n",
              "       3.18339100e-03, 2.73740869e-03, 1.64552095e-03, 2.39907728e-03,\n",
              "       2.47597078e-03, 1.67627835e-03, 9.84236832e-04, 3.53710111e-04,\n",
              "       1.18415994e-03, 1.99923106e-03, 1.10726644e-03, 2.30680507e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.53787005e-05,\n",
              "       0.00000000e+00, 1.06113033e-03, 3.18339100e-03, 3.42945021e-03,\n",
              "       3.35255671e-03, 3.32179931e-03, 3.32179931e-03, 2.50672818e-03,\n",
              "       1.95309496e-03, 1.86082276e-03, 1.87620146e-03, 2.24529027e-03,\n",
              "       2.16839677e-03, 1.35332564e-03, 2.64513649e-03, 1.01499423e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.53787005e-05, 1.53787005e-05, 1.53787005e-05,\n",
              "       0.00000000e+00, 3.07574010e-03, 3.56785852e-03, 3.56785852e-03,\n",
              "       3.58323722e-03, 3.52172241e-03, 3.42945021e-03, 3.42945021e-03,\n",
              "       3.30642061e-03, 3.27566321e-03, 2.52210688e-03, 1.95309496e-03,\n",
              "       1.89158016e-03, 3.01422530e-03, 3.52172241e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.81430219e-03, 3.46020761e-03, 3.32179931e-03,\n",
              "       3.42945021e-03, 3.50634371e-03, 3.61399462e-03, 3.49096501e-03,\n",
              "       3.44482891e-03, 3.41407151e-03, 3.44482891e-03, 3.39869281e-03,\n",
              "       3.42945021e-03, 3.76778162e-03, 2.66051519e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.96808920e-03, 3.50634371e-03, 3.35255671e-03,\n",
              "       3.27566321e-03, 3.04498270e-03, 2.76816609e-03, 3.26028451e-03,\n",
              "       3.22952710e-03, 3.24490581e-03, 3.27566321e-03, 3.42945021e-03,\n",
              "       3.38331411e-03, 3.73702422e-03, 3.10649750e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.53787005e-05, 4.61361015e-05, 0.00000000e+00,\n",
              "       1.84544406e-04, 3.36793541e-03, 3.38331411e-03, 3.26028451e-03,\n",
              "       3.35255671e-03, 2.95271050e-03, 2.59900038e-03, 3.49096501e-03,\n",
              "       3.19876970e-03, 3.35255671e-03, 3.44482891e-03, 3.26028451e-03,\n",
              "       3.47558631e-03, 3.02960400e-03, 3.21414840e-03, 7.99692426e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 9.22722030e-05, 0.00000000e+00,\n",
              "       1.52249135e-03, 3.75240292e-03, 3.41407151e-03, 3.38331411e-03,\n",
              "       3.35255671e-03, 3.12187620e-03, 3.04498270e-03, 3.39869281e-03,\n",
              "       3.30642061e-03, 3.27566321e-03, 3.41407151e-03, 3.38331411e-03,\n",
              "       3.76778162e-03, 1.83006536e-03, 2.56824298e-03, 8.61207228e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 6.15148020e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "       8.45828527e-04, 3.62937332e-03, 3.50634371e-03, 3.53710111e-03,\n",
              "       3.50634371e-03, 3.69088812e-03, 3.56785852e-03, 3.27566321e-03,\n",
              "       3.35255671e-03, 3.42945021e-03, 3.59861592e-03, 3.33717801e-03,\n",
              "       3.33717801e-03, 3.21414840e-03, 1.41484045e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.53787005e-05, 6.15148020e-05,\n",
              "       9.22722030e-05, 1.07650903e-04, 3.07574010e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.64475202e-03, 3.47558631e-03, 3.33717801e-03, 3.42945021e-03,\n",
              "       3.41407151e-03, 3.36793541e-03, 3.41407151e-03, 3.39869281e-03,\n",
              "       3.32179931e-03, 3.42945021e-03, 3.52172241e-03, 3.30642061e-03,\n",
              "       3.35255671e-03, 3.92156863e-03, 1.18415994e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.61361015e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 9.53479431e-04, 2.22991157e-03, 3.13725490e-03,\n",
              "       3.50634371e-03, 3.18339100e-03, 3.27566321e-03, 3.39869281e-03,\n",
              "       3.35255671e-03, 3.19876970e-03, 3.24490581e-03, 3.35255671e-03,\n",
              "       3.44482891e-03, 3.42945021e-03, 3.36793541e-03, 3.30642061e-03,\n",
              "       3.44482891e-03, 3.75240292e-03, 2.44521338e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.76816609e-04, 6.76662822e-04, 1.26105344e-03, 1.64552095e-03,\n",
              "       2.90657439e-03, 3.50634371e-03, 3.38331411e-03, 3.41407151e-03,\n",
              "       3.33717801e-03, 3.47558631e-03, 3.07574010e-03, 3.15263360e-03,\n",
              "       3.24490581e-03, 3.53710111e-03, 3.44482891e-03, 3.59861592e-03,\n",
              "       2.70665129e-03, 2.89119569e-03, 3.84467512e-03, 3.81391772e-03,\n",
              "       3.58323722e-03, 3.66013072e-03, 3.30642061e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 8.76585928e-04, 2.87581699e-03, 3.19876970e-03,\n",
              "       3.44482891e-03, 3.39869281e-03, 3.44482891e-03, 3.19876970e-03,\n",
              "       3.13725490e-03, 3.29104191e-03, 3.19876970e-03, 3.21414840e-03,\n",
              "       3.07574010e-03, 2.44521338e-03, 3.76778162e-03, 2.96808920e-03,\n",
              "       3.16801230e-03, 3.42945021e-03, 3.92156863e-03, 3.92156863e-03,\n",
              "       3.39869281e-03, 3.59861592e-03, 3.39869281e-03, 3.24490581e-03,\n",
              "       3.38331411e-03, 3.56785852e-03, 3.78316032e-03, 0.00000000e+00,\n",
              "       4.61361015e-05, 3.10649750e-03, 3.50634371e-03, 3.44482891e-03,\n",
              "       3.39869281e-03, 3.24490581e-03, 3.24490581e-03, 3.29104191e-03,\n",
              "       3.15263360e-03, 3.15263360e-03, 3.15263360e-03, 3.38331411e-03,\n",
              "       3.69088812e-03, 1.23029604e-03, 2.30680507e-03, 3.92156863e-03,\n",
              "       3.52172241e-03, 3.39869281e-03, 2.89119569e-03, 2.36831988e-03,\n",
              "       2.93733180e-03, 3.22952710e-03, 3.13725490e-03, 3.21414840e-03,\n",
              "       3.41407151e-03, 3.50634371e-03, 3.46020761e-03, 0.00000000e+00,\n",
              "       1.50711265e-03, 3.58323722e-03, 3.04498270e-03, 3.22952710e-03,\n",
              "       3.41407151e-03, 3.52172241e-03, 3.52172241e-03, 3.59861592e-03,\n",
              "       3.82929642e-03, 3.38331411e-03, 2.98346790e-03, 3.30642061e-03,\n",
              "       3.33717801e-03, 3.70626682e-03, 9.99615532e-04, 1.12264514e-03,\n",
              "       1.63014225e-03, 1.79930796e-03, 2.58362168e-03, 3.36793541e-03,\n",
              "       3.39869281e-03, 3.30642061e-03, 3.33717801e-03, 3.42945021e-03,\n",
              "       3.42945021e-03, 3.44482891e-03, 3.52172241e-03, 4.45982314e-04,\n",
              "       1.15340254e-03, 3.13725490e-03, 3.26028451e-03, 3.13725490e-03,\n",
              "       2.96808920e-03, 3.15263360e-03, 3.24490581e-03, 3.46020761e-03,\n",
              "       3.32179931e-03, 2.84505959e-03, 3.02960400e-03, 3.16801230e-03,\n",
              "       3.04498270e-03, 3.27566321e-03, 3.69088812e-03, 2.99884660e-03,\n",
              "       3.49096501e-03, 3.76778162e-03, 3.67550942e-03, 3.42945021e-03,\n",
              "       3.35255671e-03, 3.26028451e-03, 3.21414840e-03, 3.41407151e-03,\n",
              "       3.38331411e-03, 3.39869281e-03, 3.53710111e-03, 1.03037293e-03,\n",
              "       7.38177624e-04, 3.12187620e-03, 2.81430219e-03, 2.98346790e-03,\n",
              "       3.27566321e-03, 3.02960400e-03, 2.84505959e-03, 2.92195309e-03,\n",
              "       2.98346790e-03, 2.95271050e-03, 3.10649750e-03, 3.29104191e-03,\n",
              "       3.36793541e-03, 3.39869281e-03, 3.38331411e-03, 3.62937332e-03,\n",
              "       3.46020761e-03, 3.32179931e-03, 3.06036140e-03, 3.16801230e-03,\n",
              "       2.86043829e-03, 2.78354479e-03, 2.72202999e-03, 2.64513649e-03,\n",
              "       2.78354479e-03, 3.15263360e-03, 3.16801230e-03, 1.76855056e-03,\n",
              "       0.00000000e+00, 1.87620146e-03, 3.36793541e-03, 2.96808920e-03,\n",
              "       2.75278739e-03, 2.62975779e-03, 2.81430219e-03, 3.01422530e-03,\n",
              "       3.13725490e-03, 3.22952710e-03, 3.27566321e-03, 3.18339100e-03,\n",
              "       3.24490581e-03, 3.22952710e-03, 3.07574010e-03, 3.01422530e-03,\n",
              "       2.98346790e-03, 2.93733180e-03, 2.99884660e-03, 2.93733180e-03,\n",
              "       3.04498270e-03, 2.95271050e-03, 2.70665129e-03, 2.39907728e-03,\n",
              "       2.56824298e-03, 2.72202999e-03, 3.22952710e-03, 1.41484045e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.13802384e-03, 2.90657439e-03,\n",
              "       3.26028451e-03, 2.93733180e-03, 2.69127259e-03, 2.64513649e-03,\n",
              "       2.69127259e-03, 2.78354479e-03, 2.84505959e-03, 2.89119569e-03,\n",
              "       2.90657439e-03, 2.89119569e-03, 2.96808920e-03, 3.04498270e-03,\n",
              "       3.13725490e-03, 3.21414840e-03, 3.22952710e-03, 3.22952710e-03,\n",
              "       3.24490581e-03, 2.89119569e-03, 2.89119569e-03, 2.98346790e-03,\n",
              "       2.95271050e-03, 3.32179931e-03, 2.61437908e-03, 0.00000000e+00,\n",
              "       3.07574010e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.01499423e-03, 3.07574010e-03, 3.41407151e-03, 3.64475202e-03,\n",
              "       3.67550942e-03, 3.72164552e-03, 3.78316032e-03, 3.73702422e-03,\n",
              "       3.75240292e-03, 3.39869281e-03, 3.38331411e-03, 2.96808920e-03,\n",
              "       2.93733180e-03, 2.75278739e-03, 2.79892349e-03, 2.79892349e-03,\n",
              "       2.78354479e-03, 2.70665129e-03, 2.55286428e-03, 2.58362168e-03,\n",
              "       1.52249135e-03, 8.91964629e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.15148020e-04,\n",
              "       9.38100730e-04, 6.76662822e-04, 1.10726644e-03, 6.30526720e-04,\n",
              "       5.38254517e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_duQGtbCTTL"
      },
      "source": [
        "# Mudamos também a dimensão da base de teste\n",
        "X_test = X_test.reshape(-1, 28*28)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Lheay7FSlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f34c65-8667-40a6-edc6-e520ad6bc997"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5aDsaYSYmXD"
      },
      "source": [
        "## Etapa 4: Construindo a Rede Neural Artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l30aZ6-GYtUP"
      },
      "source": [
        "### Definindo o modelo\n",
        "\n",
        "Definimos um objeto do tipo Sequential (sequência de camadas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmfogzmn9kqv"
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg8ki6s5Cv5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894f5c20-13d8-424e-f019-ed0a9cf7aebf"
      },
      "source": [
        "model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1be1b6d080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNzLOAK5Y-mR"
      },
      "source": [
        "### Adicionando a primeira camada densa (fully-connected)\n",
        "\n",
        "Hyper-parâmetros da camada:\n",
        "- número de units/neurônios: 128\n",
        "- função de ativação: ReLU\n",
        "- input_shape (camada de entrada): (784, )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBsfDyGE-FX5"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784, )))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwqx1wZUa1rH"
      },
      "source": [
        "### Adicionando Dropout\n",
        "\n",
        "Dropout é uma técnica de regularização na qual alguns neurônios da camada tem seu valor mudado para zero, ou seja, durante o treinamento esses neurônios não serão atualizados. Com isso, temos menos chances de ocorrer overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAmpLPlr-pOX"
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqvyDvNbzwN"
      },
      "source": [
        "### Adicionando a camada de saída\n",
        "\n",
        "- units: número de classes (10 na base de dados Fashion MNIST)\n",
        "- função de ativação: softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmkUuF9Y-3mG"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRsMjsvcOua"
      },
      "source": [
        "### Compilando o modelo\n",
        "\n",
        "- Optimizer (otimizador): Adam\n",
        "- Loss (função de erro): Sparse softmax (categorical) crossentropy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbW3xeRK_CrN"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQOL_EtChrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5f8f42-efe9-4f85-ef50-eb85a5427be2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxIIFU1cany"
      },
      "source": [
        "### Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-_oLiE0_3A2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e408b784-8730-4acf-9811-c81c00e5cb0e"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.4450 - sparse_categorical_accuracy: 0.8417\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.4287 - sparse_categorical_accuracy: 0.8461\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.4133 - sparse_categorical_accuracy: 0.8525\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.4024 - sparse_categorical_accuracy: 0.8551\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3913 - sparse_categorical_accuracy: 0.8612\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3814 - sparse_categorical_accuracy: 0.8636\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3720 - sparse_categorical_accuracy: 0.8666\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3622 - sparse_categorical_accuracy: 0.8708\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3546 - sparse_categorical_accuracy: 0.8730\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3496 - sparse_categorical_accuracy: 0.8751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1bd414bc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oiLCeVHAyQy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj23nxmtcrhd"
      },
      "source": [
        "### Avaliação do modelo e previsão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nQCioOmAL7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acf58ba-67f3-435d-ee32-2421be5f0901"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 53us/sample - loss: 56.7869 - sparse_categorical_accuracy: 0.7725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozv2YVlxcx1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa8f566-c8d8-45a1-b2ed-11816132013a"
      },
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.7724999785423279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6r2eh8_Ayzb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvpH8jfvDjAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea111db9-8b33-4643-857a-3fd61d2d9bea"
      },
      "source": [
        "test_loss"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56.78685189285278"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}